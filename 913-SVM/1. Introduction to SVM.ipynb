{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "* Introduction\n",
    "* Parameters: Kernel, Regularization, Gamma and Margin\n",
    "* Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side.\n",
    "\n",
    "![](A.png)\n",
    "![](b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider what if we had data as shown in image below? Clearly, there is no line that can separate the two classes in this x-y plane. So what do we do? \n",
    "\n",
    "![](c.png)\n",
    "\n",
    "We apply transformation and add one more dimension as we call it z-axis. Lets assume value of points on z plane, w = x² + y². In this case we can manipulate it as distance of point from z-origin. Now if we plot in z-axis, a clear separation is visible and a line can be drawn .\n",
    "![](d.png)\n",
    "\n",
    "When we transform back this line to original plane, it maps to circular boundary. These transformations are called ** kernels. **\n",
    "![](e.png)\n",
    "What if data plot overlaps? Or, what in case some of the black points are inside the blue ones? \n",
    "![](f.png)\n",
    "The first one tolerates some outlier points.\n",
    "![](g.png)\n",
    "The second one is trying to achieve 0 tolerance with perfect partition.\n",
    "![](h.png)\n",
    "\n",
    "But, there is trade off. In real world application, finding perfect class for millions of training data set takes lot of time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Kernel **\n",
    "\n",
    "The learning of the hyperplane in linear SVM is done by transforming the problem using some linear algebra. This is where the kernel plays role.\n",
    "\n",
    "Polynomial and exponential kernels calculates separation line in higher dimension. This is called **kernel trick**\n",
    "\n",
    "You don’t have to guess/ derive the transformation every time for your data set. The sklearn library's SVM implementation provides it inbuilt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Regularization (C)**\n",
    "\n",
    "The Regularization parameter (often termed as C parameter in python’s sklearn library) tells the SVM optimization how much you want to avoid misclassifying each training example.\n",
    "\n",
    "For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Gamma **\n",
    "\n",
    "The gamma parameter defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. In other words, with low gamma, points far away from plausible seperation line are considered in calculation for the seperation line. Where as high gamma means the points close to plausible line are considered in calculation.\n",
    "\n",
    "![](i.png)\n",
    "![](j.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Margin **\n",
    "\n",
    "SVM to core tries to achieve a good margin.\n",
    "A margin is a separation of line to the closest class points.\n",
    "\n",
    "A good margin is one where this separation is larger for both the classes. Images below gives to visual example of good and bad margin. A good margin allows the points to be in their respective classes without crossing to other class.\n",
    "\n",
    "![](k.png)\n",
    "![](l.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

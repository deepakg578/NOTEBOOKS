{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "* Introduction\n",
    "* Why ANN\n",
    "* Perceptron\n",
    "    * Process flow\n",
    "    * Weight\n",
    "    * Bias\n",
    "    * Steps for training a Perceptron\n",
    "* Deep Learning\n",
    "* Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Neural networks are modeled after biological neural networks and attempt to allow computers to learn in a similar manner to human.\n",
    "\n",
    "The human brain has interconnected neurons with dendrites that receive inputs, and produce an electrical signal output through axon.\n",
    "![](ann.png)\n",
    "\n",
    "### Why create ANN ? \n",
    "\n",
    "There are problems in real world which is easy for computers but difficult for huan brain to solve. E.g: Multiplying large numbers 2999 * 3876\n",
    "\n",
    "Also, there are problems which are easy for human brain to solve but difficult for computers. E.g: recognizing a picture, identifying sound\n",
    "\n",
    "Neural networks try to solve problems which is easy for humans but hard for computers.\n",
    "\n",
    "### Neuron\n",
    "\n",
    "A neuron consists of one or more inputs, a processor, and a single output. Neuron follows the feed-forward model, meaning inputs are sent into the neuron are processed and reslt in an output.\n",
    "\n",
    "A perceptron process follow 5 main steps:\n",
    "* Receive inputs\n",
    "* Weight inputs\n",
    "* Sum inputs\n",
    "* Apply activation function on sum\n",
    "* Generate output\n",
    "\n",
    "![](neuron.png)\n",
    "\n",
    "#### Activation functions:\n",
    "\n",
    "* Threshold Function\n",
    "![](thres.png)\n",
    "\n",
    "* Sigmoid Function\n",
    "![](sig.png)\n",
    "\n",
    "* Rectifier function\n",
    "![](rect.png)\n",
    "\n",
    "* Hyperbolic tangent\n",
    "![](tanh.png)\n",
    "\n",
    "### How Neuron work ?\n",
    "\n",
    "Lets try to understand working of neuron with simple example:\n",
    "\n",
    "We have two inputs:\n",
    "\n",
    "Input0: x1: 12 \n",
    "\n",
    "Input1: x2: 4\n",
    "\n",
    "Each input that is sent to the neuron must first be weighted, i.e multiplied by some value(number between -1 to 1)\n",
    "![](ann2.png)\n",
    "\n",
    "When creating a perceptron, we begin with assigning random weights.\n",
    "\n",
    "Weight0: .5\n",
    "\n",
    "Weight1: -1\n",
    "\n",
    "we take each input and multiply it with its weight\n",
    "\n",
    "Input0 x Weight0 = 12 x .5 = 6\n",
    "\n",
    "Input1 x Weight1 = 4 x -1 = -4\n",
    "\n",
    "The output of a perceptron is generated by passing that sum through a activation function. In case of binary output, it tells the perceptron to \"fire\" or not.\n",
    "\n",
    "There are many activation function to choose from (Logistic, Trignometric, etc.). In our case lets consider the sign of sum. If the sum is positive number, the output is 1, else output is -1.\n",
    "\n",
    "Imagine both inputs were equal to zero, then any sum no matter what weight we give value is zero. To avoid this problem we add a third input known as **bias** input with value as 1. This avoids zero issue.\n",
    "![](ann3.png)\n",
    "\n",
    "To train a perceptron we use following steps:\n",
    "* Provide input for which there is a known answer\n",
    "* Ask the perceptron to guess the answer\n",
    "* Compute the error(How far from actual value)\n",
    "* Adjust all the weights accourding to error\n",
    "* Return to step 1 and repeat.\n",
    "\n",
    "We repeat this until we reach an error we are satisfied with.\n",
    "\n",
    "### ANN \n",
    "\n",
    "To create a neural network we link many neuron in layer. You will have input layer and output layer. Any layers between these two is called hidden layers, because you don't directly see anything but input or output.\n",
    "![](annt.png)\n",
    "\n",
    "### Deep Learning \n",
    "A Neural network with many hidden layer, causing it to be \"deep\".\n",
    "![](ann5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
